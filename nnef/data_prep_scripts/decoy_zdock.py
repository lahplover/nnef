import pandas as pd
import numpy as np
from Bio.PDB import Selection, PDBParser
import multiprocessing as mp
import os
import sys


"""
prepare docoys of protein complexes in docking benchmark 4. 
decoys are generated by zdock. 
"""

def check_overlap():
    df_t100 = pd.read_csv('training_100_protein_id.csv')
    pdb_t100 = df_t100['pdb'].apply(lambda x: x.split('_')[0]).values

    pdb_zdock = pd.read_csv('zdock_pdb_profile/zdock_pdb_list.txt')['pdb'].values

    p_list = list(set(pdb_zdock).intersection(pdb_t100))
    pd.DataFrame({'pdb': p_list}).to_csv('zdock_pdb_profile/zdock_training_100.txt', index=False)

    # df_val = pd.read_csv('local_rot_validation/flist.txt')
    # pdb_val = df_val['fname'].apply(lambda x: x.split('_')[0][3:]).values
    # p_list2 = set(pdb_zdock).intersection(pdb_val)
    # -> no overlap with validation dataset


def check_missing_residues():
    amino_acids = pd.read_csv('../../../amino_acids.csv')
    vocab_aa = [x.upper() for x in amino_acids.AA3C]
    vocab_dict = {x.upper(): y for x, y in zip(amino_acids.AA3C, amino_acids.AA)}

    pdb_id = '1AHW'
    pdb_zdock = pd.read_csv('../pdb_list.txt')['pdb'].values

    good_list = []
    for pdb_id in pdb_zdock:
        flag_list = ['_l_b', '_l_u', '_r_b', '_r_u']
        seq_list = []
        for flag in flag_list:
            p = PDBParser()

            structure = p.get_structure('X', f'{pdb_id}{flag}.pdb')

            residue_list = Selection.unfold_entities(structure, 'R')

            # bead_center_list = []
            res_name_list = []
            res_num_list = []
            # chain_list = []

            for res in residue_list:
                if res.get_resname() not in vocab_aa:
                    # raise ValueError('protein has non natural amino acids')
                    continue
                # chain_list.append(res.parent.id)
                res_name_list.append(vocab_dict[res.get_resname()])
                # res_num_list.append(res.id[1])
                # bead_center_list.append(res['CA'].get_coord())

            seq = ''.join(res_name_list)
            seq_list.append(seq)

        if (seq_list[0] == seq_list[1]) & (seq_list[2] == seq_list[3]):
            print(pdb_id)
            good_list.append(pdb_id)

    # g_center = np.vstack(bead_center_list)
    #
    # df = pd.DataFrame({'chain_id': chain_list,
    #                    'group_num': res_num_list,
    #                    'group_name': res_name_list,
    #                    'x': g_center[:, 0],
    #                    'y': g_center[:, 1],
    #                    'z': g_center[:, 2]})
    #
    # df.to_csv(f'{pdb_id}_bead.csv', index=False)


def extract_complex():
    pdb_list = pd.read_csv('pdb_list.txt')['pdb'].values
    with open('zdock.sh', 'wt') as mf:
        for pdb in pdb_list:
            mf.write(f'mkdir decoys/{pdb}/\n')
            mf.write(f'cp decoys_bm4_zd3.0.2_15deg/input_pdbs/{pdb}* decoys/{pdb}/\n')
            mf.write(f'cp decoys_bm4_zd3.0.2_15deg/results/{pdb}* decoys/{pdb}/\n')
            mf.write(f'cp decoys_bm4_zd3.0.2_15deg/create* decoys/{pdb}/\n')
            mf.write(f'cd decoys/{pdb}\n')
            mf.write(f'./create.pl {pdb}.zd3.0.2.cg.out\n')
            mf.write(f'python /home/hyang/bio/erf/erf/data_prep_scripts/decoy_zdock.py {pdb}\n')
            mf.write(f'rm -f complex*pdb\n')
            mf.write(f'cd ../..\n')


def extract_beads(pdb_path):
    amino_acids = pd.read_csv('/home/hyang/bio/erf/data/amino_acids.csv')
    vocab_aa = [x.upper() for x in amino_acids.AA3C]
    vocab_dict = {x.upper(): y for x, y in zip(amino_acids.AA3C, amino_acids.AA)}

    p = PDBParser()
    structure = p.get_structure('X', pdb_path)
    residue_list = Selection.unfold_entities(structure, 'R')

    ca_center_list = []
    cb_center_list = []
    res_name_list = []
    res_num_list = []
    chain_list = []

    for res in residue_list:
        if res.get_resname() not in vocab_aa:
            # raise ValueError('protein has non natural amino acids')
            continue

        try:
            res['CA'].get_coord()
            if res.get_resname() != 'GLY':
                res['CB'].get_coord()
        except KeyError:
            print(f'{pdb_path}, {res} missing CA / CB atoms')
            continue

        chain_list.append(res.parent.id)
        res_name_list.append(vocab_dict[res.get_resname()])
        res_num_list.append(res.id[1])

        ca_center_list.append(res['CA'].get_coord())
        if res.get_resname() != 'GLY':
            cb_center_list.append(res['CB'].get_coord())
        else:
            cb_center_list.append(res['CA'].get_coord())

    ca_center = np.vstack(ca_center_list)
    cb_center = np.vstack(cb_center_list)

    df = pd.DataFrame({'chain_id': chain_list,
                       'group_num': res_num_list,
                       'group_name': res_name_list,
                       'x': ca_center[:, 0],
                       'y': ca_center[:, 1],
                       'z': ca_center[:, 2],
                       'xcb': cb_center[:, 0],
                       'ycb': cb_center[:, 1],
                       'zcb': cb_center[:, 2]})

    # assign "chain" number for the energy calculation
    chain = np.zeros(df.shape[0], dtype=np.int)
    chain_id = df['chain_id'].values
    group_num = df['group_num'].values
    count = 0
    chain_0 = chain_id[0]
    group_0 = group_num[0]

    # if type(group_0) is str:
    #     print(pdb_id, 'group_num has string')

    for i in range(1, df.shape[0]):
        chain_i = chain_id[i]
        group_i = group_num[i]
        if (chain_i == chain_0) & (group_i == group_0 + 1):
            group_0 += 1
        else:
            count += 1
            chain_0 = chain_i
            group_0 = group_i
        chain[i] = count
    df['chain'] = chain

    df.to_csv(f'{pdb_path}_bead.csv', index=False)


# def extract_beads_all():
# pdb_id = '1HE8'
pdb_id = sys.argv[1]
root_dir = '/home/hyang/bio/erf/data/decoys/zdock/decoys/'
print(pdb_id)


def extract_batch(batch):
    for i in batch:
        if not os.path.exists(f'{root_dir}/{pdb_id}/complex.{i}.pdb_bead.csv'):
            extract_beads(f'{root_dir}/{pdb_id}/complex.{i}.pdb')


N = 3600
num = np.arange(N) + 1

num_cores = 100
batch_size = N // num_cores + 1

batch_list = []
for i in range(0, N, batch_size):
    batch = num[i:i+batch_size]
    batch_list += [batch]

with mp.Pool(processes=num_cores) as pool:
    pool.map(extract_batch, batch_list)


# if __name__ == '__main__':
#     extract_beads_all()


